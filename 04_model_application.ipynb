{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using M1 GPU (MPS backend) for inference\n"
     ]
    }
   ],
   "source": [
    "# --- Device Configuration ---\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else \"cpu\")\n",
    "print(f\"Using {'M1 GPU (MPS backend)' if device.type == 'mps' else 'CPU'} for inference\")\n",
    "\n",
    "# --- Dataset Configuration ---\n",
    "NUM_CLASSES = 7\n",
    "# Define CLASS_NAMES in alphabetical order to match training (ImageFolder ordering)\n",
    "CLASS_NAMES = ['Basalt', 'Coal', 'Granite', 'Limestone', 'Marble', 'Quartzite', 'Sandstone']\n",
    "DATA_DIR = './Dataset_Augmented/'\n",
    "\n",
    "# --- Model Setup ---\n",
    "def load_fine_tuned_model(model_path: str) -> models.ResNet:\n",
    "    \"\"\"\n",
    "    Load and configure the fine-tuned ResNet-50 model for inference.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to the saved model weights.\n",
    "    \n",
    "    Returns:\n",
    "        models.ResNet: Configured ResNet-50 model ready for inference.\n",
    "    \"\"\"\n",
    "    model = models.resnet50(weights=None)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if \"layer4\" in name or \"fc\" in name:\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # Match the fc layer structure used during training (single Linear layer, no Dropout)\n",
    "    model.fc = nn.Linear(in_features=model.fc.in_features, out_features=NUM_CLASSES)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# --- Image Preprocessing ---\n",
    "def get_preprocessing_transforms() -> transforms.Compose:\n",
    "    \"\"\"\n",
    "    Define the preprocessing pipeline for input images (matches training setup).\n",
    "    \n",
    "    Returns:\n",
    "        transforms.Compose: Preprocessing pipeline for images.\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# --- Random Image Selection ---\n",
    "def get_random_image_path(data_dir: str) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Select a random image from a random subcategory in the data directory.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Path to the data directory containing subcategories.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (path to the random image, name of the subcategory).\n",
    "    \"\"\"\n",
    "    subcategories = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "    if not subcategories:\n",
    "        raise ValueError(f\"No subcategories found in {data_dir}\")\n",
    "    \n",
    "    selected_subcategory = random.choice(subcategories)\n",
    "    subcategory_path = os.path.join(data_dir, selected_subcategory)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(subcategory_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if not image_files:\n",
    "        raise ValueError(f\"No images found in {subcategory_path}\")\n",
    "    \n",
    "    selected_image = random.choice(image_files)\n",
    "    image_path = os.path.join(subcategory_path, selected_image)\n",
    "    \n",
    "    return image_path, selected_subcategory\n",
    "\n",
    "# --- Image Classification ---\n",
    "def classify_image(image_path: str, model: models.ResNet) -> tuple[str, float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Classify an image and return the predicted class, confidence, and probabilities.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        model (models.ResNet): Fine-tuned ResNet-50 model.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (predicted class name, confidence percentage, probabilities for all classes).\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    preprocess = get_preprocessing_transforms()\n",
    "    image_tensor = preprocess(image).unsqueeze(0)\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        probabilities = probabilities.cpu().numpy()[0]\n",
    "        predicted_class_idx = torch.argmax(outputs, dim=1).item()\n",
    "\n",
    "    predicted_class = CLASS_NAMES[predicted_class_idx]\n",
    "    predicted_confidence = probabilities[predicted_class_idx] * 100\n",
    "\n",
    "    print(f\"\\nPredicted Class: {predicted_class}\")\n",
    "    print(f\"Confidence: {predicted_confidence:.2f}%\")\n",
    "    print(\"\\nConfidence Scores for All Classes:\")\n",
    "    for class_name, prob in zip(CLASS_NAMES, probabilities):\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n",
    "\n",
    "    return predicted_class, predicted_confidence, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Image Path: ./Dataset_Augmented/Sandstone/313.jpg\n",
      "Subcategory (Ground Truth): Sandstone\n",
      "\n",
      "Predicted Class: Sandstone\n",
      "Confidence: 99.82%\n",
      "\n",
      "Confidence Scores for All Classes:\n",
      "Basalt: 0.00%\n",
      "Coal: 0.01%\n",
      "Granite: 0.00%\n",
      "Limestone: 0.05%\n",
      "Marble: 0.12%\n",
      "Quartzite: 0.00%\n",
      "Sandstone: 99.82%\n",
      "\n",
      "Prediction Matches Ground Truth: True\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the fine-tuned model\n",
    "    MODEL_PATH = 'finetuned_model_resnet50.pth'\n",
    "    model = load_fine_tuned_model(MODEL_PATH)\n",
    "\n",
    "    # Select a random image from the dataset\n",
    "    try:\n",
    "        random_image_path, subcategory = get_random_image_path(DATA_DIR)\n",
    "        print(f\"\\nSelected Image Path: {random_image_path}\")\n",
    "        print(f\"Subcategory (Ground Truth): {subcategory}\")\n",
    "        \n",
    "        # Classify the random image\n",
    "        predicted_class, confidence, probabilities = classify_image(random_image_path, model)\n",
    "        \n",
    "        # Compare prediction with ground truth\n",
    "        print(f\"\\nPrediction Matches Ground Truth: {predicted_class.lower() == subcategory.lower()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggestions for Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results and loss plot, here are potential next steps:\n",
    "- **Address Overfitting:** The gap between training and validation loss suggests overfitting. Add regularization techniques like weight decay in the optimizer, or apply dropout to the fc layer\n",
    "- **Further Fine-Tuning:** Some classes (e.g., Quartzite, Basalt) show limited improvement.Unfreeze additional layers (e.g., layer3) with an even smaller learning rate to adapt more mid-level features.\n",
    "- **Data Augmentation:** Validation loss plateaus, indicating the model may need more diverse training data. Enhance training transforms with RandomRotation(), RandomAffine() to introduce more variability.\n",
    "- **Class Imbalance or Data Quality:** Marble still lags despite improvement after model fine tuning and data augmentation. Collect more Marble samples or use class-weighted loss\n",
    "- **Hyperparameter Tuning:** Perform hyperparameter tuning. Given the limited GPU constraints, this notebook does not include this part but hyperparameter tuning is a valuable next step to optimize learning rates, regularization, and scheduler settings, potentially boosting performance further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning layer4 improved the modelâ€™s performance, particularly for challenging classes like Marble, by adapting deeper features. However, overfitting and plateauing validation loss suggest room for improvement through regularization, further fine-tuning, and data augmentation. Future work should focus on enhancing generalization and addressing remaining class-specific challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rockclass_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
